{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two phase naive bayesian classifyer\n",
    "The proposed model consists of two subodels (phases). The two submodels are trained separately. During the prediction stage submodel 2 will be applied only if submodel 1 fails. In short, submodel 2 can be said to be a 'safety bag'.\n",
    "\n",
    "#### Submodel 1\n",
    "A naive bayes classifyer by **_ticket_id_** and **_station_id_**. The idea is to perform classification of passengers by stations they depart from. The problem is that the prediction query can only be answered in case the corresponding _ticket_id_ was present in the training set. That's why the second phase is required.\n",
    "\n",
    "#### Submodel 2\n",
    "A naive bayesian classiyer by **_station_id_**, **_ticket_type_nm_**, **_weekday_** and **_times of day_** this model can not utilize the ticket info and thus is less precise and more sporadic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "import warnings\n",
    "\n",
    "# auxiliary analogue of scipy.stats.mode\n",
    "def FindMostFrequentValue(array):\n",
    "    counter = { key : 0 for key in np.unique(array) }\n",
    "    for key in array:\n",
    "        counter[key] += 1\n",
    "    return max(counter, key=counter.get)\n",
    "\n",
    "\n",
    "class TwoPhaseBayesian:\n",
    "    def __init__(self):\n",
    "        # phase 1 model\n",
    "        self.ticket_id_model = []\n",
    "        # a mapping from ticket_type_nm to id for NBC\n",
    "        self.stringId2intId = []\n",
    "        # phase 2 model\n",
    "        self.NBC = []\n",
    "\n",
    "\n",
    "    def __fit_ticket_id(self, data):\n",
    "        print('Building ticket_id mapping ...')\n",
    "        reduced = data[['ticket_id', 'station_id', 'time_to_under', 'label']]\n",
    "        groups = reduced.groupby(by=['ticket_id', 'station_id'])\n",
    "        # compute average travel time for each passenger departing from specific station\n",
    "        # and most common (max likelihood) destination (label)\n",
    "        self.ticket_id_model = groups.agg({\n",
    "            'time_to_under' : 'mean',\n",
    "            'label' : FindMostFrequentValue\n",
    "        })\n",
    "\n",
    "\n",
    "    def __prepare_nbc_input(self, data):\n",
    "        reduced = data[['ticket_type_nm', 'station_id', 'pass_dttm']]\n",
    "        # Replace ticket_id strings with integers\n",
    "        reduced.loc[:, 'ticket_type_nm'] = reduced.loc[:, 'ticket_type_nm'].apply(lambda name : self.stringId2intId[name])\n",
    "        reduced.rename(columns={'ticket_type_nm' : 'ticket_type_id'}, inplace=True)\n",
    "        # extract week day from date\n",
    "        reduced.loc[:, 'weekday'] = reduced.loc[:, 'pass_dttm'].apply(lambda date : date.weekday())\n",
    "        # extract time from date\n",
    "        reduced.loc[:, 'dayhour'] = reduced.loc[:, 'pass_dttm'].apply(lambda date : date.hour)\n",
    "        X_data = reduced.loc[:, ['ticket_type_id', 'station_id', 'weekday', 'dayhour']]\n",
    "        return X_data\n",
    "\n",
    "\n",
    "    def __fit_nbc(self, data):\n",
    "        print('Building Naive Bayesian classifyer ...')\n",
    "        # prepare stringId2intId\n",
    "        names = np.unique(data['ticket_type_nm'])\n",
    "        self.stringId2intId = { names[idx] : idx for idx in range(names.size) }\n",
    "        # fit NBC\n",
    "        print('Preparing training data ...')\n",
    "        X_train = self.__prepare_nbc_input(data)\n",
    "        Y_train = data.loc[:, 'label'].to_numpy()\n",
    "        print('Training Naive Bayesian Classifyer ...')\n",
    "        self.NBC = CategoricalNB()\n",
    "        self.NBC.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "    def fit(self, data):\n",
    "        warnings.filterwarnings('ignore')\n",
    "        self.__fit_ticket_id(data)\n",
    "        self.__fit_nbc(data)\n",
    "        print('DONE')\n",
    "\n",
    "\n",
    "    def predict(self, data):\n",
    "        answers = pd.DataFrame({\n",
    "            'time_to_under' : np.zeros(data.shape[0]),\n",
    "            'label' : np.zeros(data.shape[0])\n",
    "        })\n",
    "        reduced = data[['ticket_id', 'ticket_type_nm', 'station_id', 'pass_dttm']]\n",
    "\n",
    "        matching_ticket_id = \\\n",
    "            data[['ticket_id', 'station_id']] \\\n",
    "            .apply(lambda row : (row[0], row[1]) in self.ticket_id_model.index, axis=1)\n",
    "        match_by_ticket_index = matching_ticket_id[matching_ticket_id].index\n",
    "        match_by_nbc_index = matching_ticket_id[~matching_ticket_id].index\n",
    "\n",
    "        # trying to match by ticket_id\n",
    "        print(f'Matching {match_by_ticket_index.size} passengers by ticket_id predictor ...')\n",
    "        match_by_ticket = data.loc[match_by_ticket_index, :]\n",
    "        match_by_ticket.reset_index(inplace=True)\n",
    "        X_data = [\n",
    "            [match_by_ticket.loc[i, 'ticket_id'], match_by_ticket.loc[i, 'station_id']]\n",
    "            for i in range(match_by_ticket.shape[0])]\n",
    "        Y_prediction = self.ticket_id_model.loc[X_data]\n",
    "        answers.loc[match_by_ticket_index] = Y_prediction.to_numpy()\n",
    "\n",
    "        # in case ticket_id is not present, use a weaker Naive Bayes\n",
    "        print(f'Matching {match_by_nbc_index.size} passengers via NBC ...')\n",
    "        match_by_nbc = data.loc[match_by_nbc_index, :]\n",
    "        match_by_nbc.reset_index(inplace=True)\n",
    "        default_name = list(self.stringId2intId.keys())[0]\n",
    "        match_by_nbc.loc[:, 'ticket_type_nm'] = \\\n",
    "            match_by_nbc.loc[:, 'ticket_type_nm'] \\\n",
    "            .apply(lambda name :\n",
    "                    name if name in self.stringId2intId.keys() else default_name)\n",
    "        X_data = self.__prepare_nbc_input(match_by_nbc)\n",
    "        Y_labels = self.NBC.predict(X_data)\n",
    "        answers.iloc[match_by_nbc_index, 1] = Y_labels\n",
    "        answers.iloc[match_by_nbc_index, 0] = 500 # dummy\n",
    "\n",
    "        return answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_dataset_train.csv', parse_dates=['pass_dttm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.1)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ticket_id mapping ...\n",
      "Building Naive Bayesian classifyer ...\n",
      "Preparing training data ...\n",
      "Training Naive Bayesian Classifyer ...\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "model = TwoPhaseBayesian()\n",
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching 90233 passengers by ticket_id predictor ...\n",
      "Matching 18870 passengers via NBC ...\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct label predictions pct |  57.8%\n",
      "R2 score of time_to_under:    |  0.262\n",
      "Total score:                  |  0.42\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "label_prediction = prediction.loc[:, 'label'].to_numpy().astype(int)\n",
    "label_expected = test.loc[:, 'label'].to_numpy()\n",
    "tp_rate = np.sum(label_prediction == label_expected) / label_expected.size\n",
    "print(f'Correct label predictions pct | {100 * tp_rate : .1f}%')\n",
    "\n",
    "time_prediction = prediction.loc[:, 'time_to_under'].to_numpy()\n",
    "time_expected = test.loc[:, 'time_to_under'].to_numpy()\n",
    "r2 = r2_score(time_expected, time_prediction)\n",
    "print(f'R2 score of time_to_under:    | {r2 : .3f}')\n",
    "\n",
    "print(f'Total score:                  | {(r2 + tp_rate) / 2 : .2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 02:22:02) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9372c4ef64394110d726c5e6ad1f138df83bd28467af0d4cf80335b1bdaefe41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
